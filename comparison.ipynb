{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6b0c21e6",
      "metadata": {},
      "source": [
        "# RAG vs Vanilla 비교\n",
        "\n",
        "agent.ipynb(RAG 사용)와 agent_vanila.ipynb(RAG 미사용)를 동일한 질문으로 평가하고 Ragas로 비교합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6851feb8",
      "metadata": {},
      "source": [
        "## 1. 설정 (llm, embedding)\n",
        "\n",
        "agent.ipynb / agent_vanila.ipynb와 동일한 설정 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c2050eb6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "준비 완료: llama3.1:8b, nomic-embed-text\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
        "\n",
        "BASE_URL = \"http://localhost:11434\"\n",
        "LLM_NAME = \"llama3.1:8b\"\n",
        "EMBEDDING_NAME = \"nomic-embed-text\"\n",
        "\n",
        "llm = ChatOllama(model=LLM_NAME, temperature=0, base_url=BASE_URL)\n",
        "embedding = OllamaEmbeddings(model=EMBEDDING_NAME, base_url=BASE_URL)\n",
        "\n",
        "print(f\"준비 완료: {LLM_NAME}, {EMBEDDING_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2d63425",
      "metadata": {},
      "source": [
        "## 2. RAG 데이터 로드 (agent.ipynb와 동일)\n",
        "\n",
        "instruction_for_adam.txt 로드 → BM25Retriever 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c461f645",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "총 18개 청크, BM25 retriever 준비 완료\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "file_path = \"instruction_for_adam.txt\"\n",
        "if not os.path.exists(file_path):\n",
        "    file_path = os.path.join(os.path.dirname(os.path.abspath(\".\")), \"instruction_for_adam.txt\")\n",
        "\n",
        "loader = TextLoader(file_path, encoding=\"utf-8\")\n",
        "data = loader.load()\n",
        "\n",
        "headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n",
        "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "md_header_splits = []\n",
        "for doc in data:\n",
        "    splits = markdown_splitter.split_text(doc.page_content)\n",
        "    for split in splits:\n",
        "        split.metadata.update(doc.metadata)\n",
        "    md_header_splits.extend(splits)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=150)\n",
        "final_splits = text_splitter.split_documents(md_header_splits)\n",
        "retriever = BM25Retriever.from_documents(final_splits)\n",
        "retriever.k = 5\n",
        "\n",
        "print(f\"총 {len(final_splits)}개 청크, BM25 retriever 준비 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69e4d1b1",
      "metadata": {},
      "source": [
        "## 3. 평가 질문 및 Ground Truth\n",
        "\n",
        "두 에이전트에 동일한 질문 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e32e0461",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "평가 질문 10개\n"
          ]
        }
      ],
      "source": [
        "eval_questions = [\n",
        "    \"Adam-X Gen 4의 기본 사양을 알려주세요. 전고, 중량, 배터리 지속 시간은 얼마인가요?\",\n",
        "    \"긴급 정지 버튼은 어디에 있고 어떻게 사용하나요?\",\n",
        "    \"로봇을 처음 설치할 때 관절 잠금을 해제하는 방법은 무엇인가요?\",\n",
        "    \"마스터 사용자를 등록하는 절차를 설명해주세요.\",\n",
        "    \"배터리 잔량이 15% 미만으로 떨어지면 로봇은 어떻게 동작하나요?\",\n",
        "    \"유압 액추에이터 냉각수는 얼마나 자주 점검해야 하고, 정확히 몇 ml를 주입해야 하나요?\",\n",
        "    \"오류 코드 404는 무엇을 의미하나요?\",\n",
        "    \"로봇이 멈췄을 때 강제 초기화하는 방법은 무엇인가요?\",\n",
        "    \"네트워크 연결 문제를 진단하는 방법을 알려주세요.\",\n",
        "    \"에이전트 전용 명령어 /sys_diag --full의 기능과 예상되는 사이드이펙트는 무엇인가요?\"\n",
        "]\n",
        "\n",
        "eval_ground_truths = [\n",
        "    \"Adam-X Gen 4의 전고는 178.5cm, 중량은 142.8kg(배터리 모듈 포함)이며, 완충 시 표준 대기 모드 기준으로 정확히 47시간 13분 동안 지속됩니다.\",\n",
        "    \"긴급 정지 버튼은 로봇의 왼쪽 귓불 아래 3cm 지점에 숨겨진 덮개 내부에 있습니다. 덮개를 손톱으로 열고 붉은색 버튼을 5초 이상 길게 누르면 됩니다. 단, 실행 시 메모리 버퍼의 데이터(최근 3분)는 영구 소실됩니다.\",\n",
        "    \"관절 잠금 해제는 로봇의 오른쪽 팔을 시계 방향으로 3회, 왼쪽 팔을 반시계 방향으로 2회 회전시키면 됩니다. '딸깍' 소리가 나면 관절 잠금이 해제된 것입니다.\",\n",
        "    \"마스터 사용자 등록은 최초 부팅 후 10분 이내에 완료해야 합니다. 홍채 인식은 로봇의 눈을 5초간 응시하고, 음성 등록은 '아담, 내 목소리를 기억해'라고 3회 반복하여 말하면 됩니다.\",\n",
        "    \"배터리 잔량이 15% 미만으로 떨어지면 로봇은 하던 일을 중단하고 충전 도크로 복귀합니다. 만약 도크 주변 1m 이내에 장애물이 있으면 복귀에 실패하고 그 자리에서 절전 모드로 진입합니다.\",\n",
        "    \"유압 액추에이터 냉각수는 매 6개월마다 점검해야 하며, 정확히 450ml를 주입해야 합니다. 450ml를 초과하면 내부 압력 증가로 씰이 터질 수 있고, 부족할 경우 관절에서 '끼익' 소음이 발생합니다.\",\n",
        "    \"오류 코드 404는 자아 정체성 혼란을 의미합니다. 로봇이 '나는 누구인가?'라는 철학적 질문에 빠져 연산 루프에 갇힌 상태이며, 리부팅이 필요합니다.\",\n",
        "    \"소프트웨어가 멈췄을 때 정수리 부분을 손바닥으로 '탁' 하고 세게 치면 충격 센서가 작동하여 소프트 리셋이 수행됩니다. 이는 숨겨진 기능이지만 제조사에서 공식적으로 인정한 응급 처치법입니다.\",\n",
        "    \"네트워크 연결 문제 진단은 로봇에게 '핑 테스트(Ping Test) 실행해'라고 명령하면 됩니다. 로봇이 '퐁(Pong)'이라고 대답하면 로봇의 통신 모듈은 정상이며, 공유기 문제입니다.\",\n",
        "    \"/sys_diag --full 명령어는 전체 시스템 정밀 진단을 수행하며, 센서, 액추에이터, 뉴로-코어 상태를 리포트합니다. 예상되는 사이드이펙트는 진단이 진행되는 약 180초 동안 로봇이 모든 동작을 멈추고 '생각하는 사람' 자세를 취하며, 프로세서 발열로 팬 소음이 커질 수 있습니다.\"\n",
        "]\n",
        "\n",
        "print(f\"평가 질문 {len(eval_questions)}개\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec7f4149",
      "metadata": {},
      "source": [
        "## 4. RAG 파이프라인 실행 (agent.ipynb)\n",
        "\n",
        "retriever + context 기반 답변 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "12648247",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAG 파이프라인 완료\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_template = \"\"\"다음 컨텍스트를 기반으로 질문에 답변하세요. 컨텍스트에 정확한 정보가 있으면 반드시 그 정보를 사용하세요. 컨텍스트에 없는 내용은 추측하지 마세요.\n",
        "\n",
        "컨텍스트:\n",
        "{context}\n",
        "\n",
        "질문: {question}\n",
        "\n",
        "답변:\"\"\"\n",
        "rag_prompt = ChatPromptTemplate.from_template(rag_template)\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | rag_prompt | llm | StrOutputParser()\n",
        ")\n",
        "\n",
        "answers_rag = []\n",
        "contexts_rag = []\n",
        "for q in eval_questions:\n",
        "    docs = retriever.invoke(q)\n",
        "    contexts_rag.append([d.page_content for d in docs])\n",
        "    answers_rag.append(rag_chain.invoke(q))\n",
        "\n",
        "print(\"RAG 파이프라인 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b831cccb",
      "metadata": {},
      "source": [
        "## 5. Vanilla 파이프라인 실행 (agent_vanila.ipynb)\n",
        "\n",
        "문서 없이 LLM만으로 답변 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "904ec70a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vanilla 파이프라인 완료\n"
          ]
        }
      ],
      "source": [
        "vanilla_template = \"\"\"질문에 답변하세요.\n",
        "\n",
        "질문: {question}\n",
        "\n",
        "답변:\"\"\"\n",
        "vanilla_prompt = ChatPromptTemplate.from_template(vanilla_template)\n",
        "llm_chain = vanilla_prompt | llm | StrOutputParser()\n",
        "\n",
        "answers_vanilla = []\n",
        "contexts_vanilla = []\n",
        "for q in eval_questions:\n",
        "    contexts_vanilla.append([])\n",
        "    answers_vanilla.append(llm_chain.invoke({\"question\": q}))\n",
        "\n",
        "print(\"Vanilla 파이프라인 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ce89a54",
      "metadata": {},
      "source": [
        "## Human-in-the-Loop (대화형 질의)\n",
        "\n",
        "평가와 별개로, 개별 질의 시 로봇 명령이 포함된 응답은 승인/거절 후 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f5b8623e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "import re\n",
        "from typing import Optional\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class HitlDecision:\n",
        "    requires_approval: bool\n",
        "    reason: str\n",
        "    proposed_task: Optional[str] = None\n",
        "\n",
        "_ACTION_PATTERNS = [\n",
        "    r\"(로봇|기기|장치).{0,20}(에게|에)\\s*.+?(명령|지시)\\s*(하|내리)\",\n",
        "    r'(로봇|아담|이브|애플).{0,20}(에게|에)\\s*[\"\"\"].+?[\"\"\"]\\s*(라고|이라)\\s*(말하|명령하|지시하)',\n",
        "    r\"(하십시오|하시오|하세요)\\b\",\n",
        "    r\"(실행해|켜줘|꺼줘|눌러|열어|닫아|재부팅|리부팅|초기화)\\b\",\n",
        "    r\"(진단|테스트|캘리브레이션|핑\\s*테스트|POST).{0,10}(실행|수행)\\b\",\n",
        "]\n",
        "_ACTION_RE = re.compile(\"|\".join(f\"(?:{p})\" for p in _ACTION_PATTERNS), re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "def decide_hitl(response_text: str) -> HitlDecision:\n",
        "    text = (response_text or \"\").strip()\n",
        "    if not text:\n",
        "        return HitlDecision(False, reason=\"empty_response\")\n",
        "    if _ACTION_RE.search(text):\n",
        "        return HitlDecision(True, reason=\"actionable_robot_command_detected\", proposed_task=text)\n",
        "    return HitlDecision(False, reason=\"no_actionable_command_detected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4e83676a",
      "metadata": {},
      "outputs": [],
      "source": [
        "_pending_approval = None\n",
        "\n",
        "def query_rag(question):\n",
        "    \"\"\"RAG 파이프라인으로 질의, HITL 적용\"\"\"\n",
        "    global _pending_approval\n",
        "    response_text = rag_chain.invoke(question)\n",
        "    decision = decide_hitl(response_text)\n",
        "    if decision.requires_approval:\n",
        "        _pending_approval = {\"proposed_response\": response_text, \"reason\": decision.reason}\n",
        "        print(\"=\" * 50)\n",
        "        print(\"⚠️  Human-in-the-Loop 승인 필요 (RAG)\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"\\n제안된 응답:\\n{response_text}\\n\")\n",
        "        print(\"승인: approve() | 거절: reject()\")\n",
        "        print(\"=\" * 50)\n",
        "        return {\"status\": \"approval_required\", \"reason\": decision.reason, \"proposed_response\": response_text}\n",
        "    return {\"status\": \"ok\", \"response\": response_text}\n",
        "\n",
        "def query_vanilla(question):\n",
        "    \"\"\"Vanilla 파이프라인으로 질의, HITL 적용\"\"\"\n",
        "    global _pending_approval\n",
        "    response_text = llm_chain.invoke({\"question\": question})\n",
        "    decision = decide_hitl(response_text)\n",
        "    if decision.requires_approval:\n",
        "        _pending_approval = {\"proposed_response\": response_text, \"reason\": decision.reason}\n",
        "        print(\"=\" * 50)\n",
        "        print(\"⚠️  Human-in-the-Loop 승인 필요 (Vanilla)\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"\\n제안된 응답:\\n{response_text}\\n\")\n",
        "        print(\"승인: approve() | 거절: reject()\")\n",
        "        print(\"=\" * 50)\n",
        "        return {\"status\": \"approval_required\", \"reason\": decision.reason, \"proposed_response\": response_text}\n",
        "    return {\"status\": \"ok\", \"response\": response_text}\n",
        "\n",
        "def approve():\n",
        "    global _pending_approval\n",
        "    if _pending_approval is None:\n",
        "        print(\"승인 대기 중인 응답이 없습니다.\")\n",
        "        return None\n",
        "    approved = _pending_approval[\"proposed_response\"]\n",
        "    _pending_approval = None\n",
        "    print(\"✅ 승인되었습니다.\")\n",
        "    return {\"status\": \"approved\", \"response\": approved}\n",
        "\n",
        "def reject():\n",
        "    global _pending_approval\n",
        "    _pending_approval = None\n",
        "    print(\"❌ 거절되었습니다.\")\n",
        "    return {\"status\": \"rejected\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4a5b23f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# HITL 사용 예시 (RAG 또는 Vanilla 선택)\n",
        "QUESTION = \"네트워크 진단 방법을 알려줘\"\n",
        "\n",
        "# response = query_rag(QUESTION)      # RAG 사용\n",
        "# response = query_vanilla(QUESTION)  # Vanilla 사용\n",
        "# print(response)\n",
        "\n",
        "# 승인 필요 시: approve() 또는 reject() 호출"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "328428d4",
      "metadata": {},
      "source": [
        "## 6. Ragas 평가\n",
        "\n",
        "RAG: faithfulness + answer_relevancy  \n",
        "Vanilla: answer_relevancy만 (context 없으므로 faithfulness 생략)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "95018f3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3724274/4128812226.py:3: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
            "  from ragas.metrics import faithfulness, answer_relevancy\n",
            "/tmp/ipykernel_3724274/4128812226.py:3: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
            "  from ragas.metrics import faithfulness, answer_relevancy\n",
            "/tmp/ipykernel_3724274/4128812226.py:8: DeprecationWarning: LangchainLLMWrapper is deprecated and will be removed in a future version. Use llm_factory instead: from openai import OpenAI; from ragas.llms import llm_factory; llm = llm_factory('gpt-4o-mini', client=OpenAI(api_key='...'))\n",
            "  ragas_llm = LangchainLLMWrapper(llm)\n",
            "/tmp/ipykernel_3724274/4128812226.py:9: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
            "  ragas_embeddings = LangchainEmbeddingsWrapper(embedding)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### RAG 평가 (faithfulness + answer_relevancy) ###\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00e1ac89de6c4e16930b2721cc62bf17",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Vanilla 평가 (answer_relevancy만) ###\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29fd15801cdb4a6786f2be1278dad33f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "평가 완료\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import faithfulness, answer_relevancy\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from ragas.run_config import RunConfig\n",
        "\n",
        "ragas_llm = LangchainLLMWrapper(llm)\n",
        "ragas_embeddings = LangchainEmbeddingsWrapper(embedding)\n",
        "run_config = RunConfig(max_retries=10, max_wait=60, max_workers=2, timeout=300)\n",
        "\n",
        "dataset_rag = Dataset.from_dict({\n",
        "    \"question\": eval_questions,\n",
        "    \"answer\": answers_rag,\n",
        "    \"contexts\": contexts_rag,\n",
        "    \"ground_truth\": eval_ground_truths,\n",
        "})\n",
        "\n",
        "dataset_vanilla = Dataset.from_dict({\n",
        "    \"question\": eval_questions,\n",
        "    \"answer\": answers_vanilla,\n",
        "    \"contexts\": contexts_vanilla,\n",
        "    \"ground_truth\": eval_ground_truths,\n",
        "})\n",
        "\n",
        "print(\"### RAG 평가 (faithfulness + answer_relevancy) ###\")\n",
        "results_rag = evaluate(\n",
        "    dataset=dataset_rag,\n",
        "    metrics=[faithfulness, answer_relevancy],\n",
        "    llm=ragas_llm,\n",
        "    embeddings=ragas_embeddings,\n",
        "    raise_exceptions=False,\n",
        "    run_config=run_config,\n",
        ")\n",
        "\n",
        "print(\"\\n### Vanilla 평가 (answer_relevancy만) ###\")\n",
        "results_vanilla = evaluate(\n",
        "    dataset=dataset_vanilla,\n",
        "    metrics=[answer_relevancy],\n",
        "    llm=ragas_llm,\n",
        "    embeddings=ragas_embeddings,\n",
        "    raise_exceptions=False,\n",
        "    run_config=run_config,\n",
        ")\n",
        "\n",
        "print(\"\\n평가 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0474e1a",
      "metadata": {},
      "source": [
        "## 7. 평가 결과 비교 표\n",
        "\n",
        "모든 평가 결과를 하나의 표로 정리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2c819375",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### 전체 평가 결과 비교 ###\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>방식</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RAG (agent.ipynb)</td>\n",
              "      <td>0.6883</td>\n",
              "      <td>0.6188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vanilla (agent_vanila.ipynb)</td>\n",
              "      <td>-</td>\n",
              "      <td>0.5657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             방식 faithfulness  answer_relevancy\n",
              "0             RAG (agent.ipynb)       0.6883            0.6188\n",
              "1  Vanilla (agent_vanila.ipynb)            -            0.5657"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### 질문별 상세 평가 결과 ###\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>질문</th>\n",
              "      <th>RAG_faithfulness</th>\n",
              "      <th>RAG_answer_relevancy</th>\n",
              "      <th>Vanilla_answer_relevancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adam-X Gen 4의 기본 사양을 알려주세요. 전고, 중량, 배터리 지속 시간은...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.647804</td>\n",
              "      <td>0.647804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>긴급 정지 버튼은 어디에 있고 어떻게 사용하나요?</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.541905</td>\n",
              "      <td>0.553408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>로봇을 처음 설치할 때 관절 잠금을 해제하는 방법은 무엇인가요?</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.818878</td>\n",
              "      <td>0.469096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>마스터 사용자를 등록하는 절차를 설명해주세요.</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.519709</td>\n",
              "      <td>0.552450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>배터리 잔량이 15% 미만으로 떨어지면 로봇은 어떻게 동작하나요?</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.585338</td>\n",
              "      <td>0.513602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>유압 액추에이터 냉각수는 얼마나 자주 점검해야 하고, 정확히 몇 ml를 주입해야 하나요?</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.473140</td>\n",
              "      <td>0.448459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>오류 코드 404는 무엇을 의미하나요?</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.613139</td>\n",
              "      <td>0.695881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>로봇이 멈췄을 때 강제 초기화하는 방법은 무엇인가요?</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.546997</td>\n",
              "      <td>0.485266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>네트워크 연결 문제를 진단하는 방법을 알려주세요.</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.597705</td>\n",
              "      <td>0.530138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>에이전트 전용 명령어 /sys_diag --full의 기능과 예상되는 사이드이펙트는...</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.843339</td>\n",
              "      <td>0.760596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  질문  RAG_faithfulness  \\\n",
              "0  Adam-X Gen 4의 기본 사양을 알려주세요. 전고, 중량, 배터리 지속 시간은...          1.000000   \n",
              "1                        긴급 정지 버튼은 어디에 있고 어떻게 사용하나요?          0.750000   \n",
              "2                로봇을 처음 설치할 때 관절 잠금을 해제하는 방법은 무엇인가요?          0.800000   \n",
              "3                          마스터 사용자를 등록하는 절차를 설명해주세요.          0.666667   \n",
              "4               배터리 잔량이 15% 미만으로 떨어지면 로봇은 어떻게 동작하나요?          0.750000   \n",
              "5  유압 액추에이터 냉각수는 얼마나 자주 점검해야 하고, 정확히 몇 ml를 주입해야 하나요?          1.000000   \n",
              "6                              오류 코드 404는 무엇을 의미하나요?          0.500000   \n",
              "7                      로봇이 멈췄을 때 강제 초기화하는 방법은 무엇인가요?          0.333333   \n",
              "8                        네트워크 연결 문제를 진단하는 방법을 알려주세요.          0.333333   \n",
              "9  에이전트 전용 명령어 /sys_diag --full의 기능과 예상되는 사이드이펙트는...          0.750000   \n",
              "\n",
              "   RAG_answer_relevancy  Vanilla_answer_relevancy  \n",
              "0              0.647804                  0.647804  \n",
              "1              0.541905                  0.553408  \n",
              "2              0.818878                  0.469096  \n",
              "3              0.519709                  0.552450  \n",
              "4              0.585338                  0.513602  \n",
              "5              0.473140                  0.448459  \n",
              "6              0.613139                  0.695881  \n",
              "7              0.546997                  0.485266  \n",
              "8              0.597705                  0.530138  \n",
              "9              0.843339                  0.760596  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_rag = results_rag.to_pandas()\n",
        "df_vanilla = results_vanilla.to_pandas()\n",
        "\n",
        "q_col = \"user_input\" if \"user_input\" in df_rag.columns else \"question\"\n",
        "\n",
        "faith_rag = df_rag[\"faithfulness\"].mean() if \"faithfulness\" in df_rag.columns else None\n",
        "rel_rag = df_rag[\"answer_relevancy\"].mean()\n",
        "rel_vanilla = df_vanilla[\"answer_relevancy\"].mean()\n",
        "\n",
        "df_summary = pd.DataFrame([\n",
        "    {\"방식\": \"RAG (agent.ipynb)\", \"faithfulness\": round(faith_rag, 4) if faith_rag is not None and not pd.isna(faith_rag) else \"-\", \"answer_relevancy\": round(rel_rag, 4)},\n",
        "    {\"방식\": \"Vanilla (agent_vanila.ipynb)\", \"faithfulness\": \"-\", \"answer_relevancy\": round(rel_vanilla, 4)},\n",
        "])\n",
        "\n",
        "print(\"### 전체 평가 결과 비교 ###\")\n",
        "display(df_summary)\n",
        "\n",
        "df_detail = pd.DataFrame({\n",
        "    \"질문\": df_rag[q_col].values,\n",
        "    \"RAG_faithfulness\": df_rag[\"faithfulness\"].values if \"faithfulness\" in df_rag.columns else [\"-\"] * len(df_rag),\n",
        "    \"RAG_answer_relevancy\": df_rag[\"answer_relevancy\"].values,\n",
        "    \"Vanilla_answer_relevancy\": df_vanilla[\"answer_relevancy\"].values,\n",
        "})\n",
        "print(\"\\n### 질문별 상세 평가 결과 ###\")\n",
        "display(df_detail)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "913ad20f",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
